{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXb4gnmoOQeGQj+HxQEupp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Machine-Learning-Assignments/blob/main/Assignment_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is the difference between supervised and unsupervised learning? Give some examples to illustrate your point.\n",
        "\n",
        "The main difference between supervised and unsupervised learning: Labeled data. The main distinction between the two approaches is the use of labeled datasets. To put it simply, supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not.\n",
        "\n",
        "Supervised Learning includes various algorithms such as Bayesian Logic, Decision Tree, Logistic Regression, Linear Regression, Multi-class Classification, Support Vector Machine\n",
        "\n",
        "Unsupervised Learning includes various algorithms like KNN, Apriori Algorithm, and Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "y3wN3obCS9tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Mention a few unsupervised learning applications.\n",
        "\n",
        "The main applications of unsupervised learning include clustering, visualization, dimensionality reduction, finding association rules, and anomaly detection"
      ],
      "metadata": {
        "id": "7Ui7CmSfTKoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What are the three main types of clustering methods? Briefly describe the characteristics of each.\n",
        "\n",
        "Types of Clustering\n",
        "\n",
        "Centroid-based Clustering.\n",
        "Density-based Clustering.\n",
        "Distribution-based Clustering.\n",
        "Hierarchical Clustering."
      ],
      "metadata": {
        "id": "RhQCJSVPTVON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Explain how the k-means algorithm determines the consistency of clustering.\n",
        "\n",
        "K-means allocates every data point in the dataset to the nearest centroid (minimizing Euclidean distances between them), meaning that a data point is considered to be in a particular cluster if it is closer to that cluster's centroid than any other centroid.\n",
        "\n",
        "A K-means clustering algorithm tries to group similar items in the form of clusters. The number of groups is represented by K. Let's take an example. ... If you will notice here then you will find that they are forming a group or cluster, where each of the vegetables is kept within their kind of group forming the clusters"
      ],
      "metadata": {
        "id": "fj9lntbOThz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. With a simple illustration, explain the key difference between the k-means and k-medoids algorithms.\n",
        "\n",
        "K-means attempts to minimize the total squared error, while k-medoids minimizes the sum of dissimilarities between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k -means algorithm, k -medoids chooses datapoints as centers ( medoids or exemplars)"
      ],
      "metadata": {
        "id": "8_Q4YFa-TrQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is a dendrogram, and how does it work? Explain how to do it.\n",
        "\n",
        "A dendrogram is a diagram that shows the attribute distances between each pair of sequentially merged classes. To avoid crossing lines, the diagram is graphically arranged so that members of each pair of classes to be merged are neighbors in the diagram. The Dendrogram tool uses a hierarchical clustering algorithm.\n",
        "\n"
      ],
      "metadata": {
        "id": "4QLCzgRLTxMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What exactly is SSE? What role does it play in the k-means algorithm?\n",
        "\n",
        "First of all compute the sum of squared error(SSE) for some value of K. SSE is defined as the sum of the squared distance between centroid and each member of the cluster.\n",
        "\n",
        "A K-means clustering algorithm tries to group similar items in the form of clusters. The number of groups is represented by K. ... If you will notice here then you will find that they are forming a group or cluster, where each of the vegetables is kept within their kind of group forming the clusters"
      ],
      "metadata": {
        "id": "CWdr7x1AT7Ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.With a step-by-step algorithm, explain the k-means procedure.\n",
        "\n",
        "Step 1: Choose the number of clusters k. \n",
        "Step 2: Select k random points from the data as centroids.\n",
        "Step 3: Assign all the points to the closest cluster centroid. \n",
        "Step 4: Recompute the centroids of newly formed clusters. \n",
        "Step 5: Repeat steps 3 and 4."
      ],
      "metadata": {
        "id": "3-ewrhrcUII4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.In the sense of hierarchical clustering, define the terms single link and complete link.\n",
        "\n",
        "In single-link (or single linkage) hierarchical clustering, we merge in each step the two clusters whose two closest members have the smallest distance (or: the two clusters with the smallest minimum pairwise distance). Complete-link clustering can also be described using the concept of clique."
      ],
      "metadata": {
        "id": "MvkyZRB4UQgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How does the apriori concept aid in the reduction of measurement overhead in a business basket analysis? Give an example to demonstrate your point.\n",
        "\n",
        "Apriori algorithm assumes that any subset of a frequent itemset must be frequent. Its the algorithm behind Market Basket Analysis. So, according to the principle of Apriori, if {Grapes, Apple, Mango} is frequent, then {Grapes, Mango} must also be frequent. Here is a dataset consisting of six transactions"
      ],
      "metadata": {
        "id": "BSqyQdkAUWTm"
      }
    }
  ]
}