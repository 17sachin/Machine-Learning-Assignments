{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNx1QR/NNos9d5wYV03wz3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Machine-Learning-Assignments/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.In the sense of machine learning, what is a model? What is the best way to train a model?\n",
        "\n",
        "A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.\n",
        "\n",
        "3 steps to training a machine learning model\n",
        "\n",
        "Step 1: Begin with existing data. Machine learning requires us to have existing data—not the data our application will use when we run it, but data to learn from. \n",
        "\n",
        "Step 2: Analyze data to identify patterns.\n",
        "\n",
        "Step 3: Make predictions.\n"
      ],
      "metadata": {
        "id": "t-TJk-Fq8ecX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.In the sense of machine learning, explain the 'No Free Lunch' theorem.\n",
        "\n",
        "The “no free lunch” (NFL) theorem for supervised machine learning is a theorem that essentially implies that no single machine learning algorithm is universally the best-performing algorithm for all problems.\n"
      ],
      "metadata": {
        "id": "zGw1zlzA87m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Describe the K-fold cross-validation mechanism in detail.\n",
        "\n",
        "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. Take the group as a hold out or test data set. \n",
        "\n",
        "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data"
      ],
      "metadata": {
        "id": "Q9_Vvlf39eL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Describe the bootstrap sampling method. What is the aim of it?\n",
        "\n",
        "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.  The bootstrap method involves iteratively resampling a dataset with replacement. That when using the bootstrap you must choose the size of the sample and the number of repeats.\n",
        "\n"
      ],
      "metadata": {
        "id": "tVsp1wmm-VY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results.\n",
        "\n",
        "Kappa is used in classification as a measure of agreement between observed and predicted or inferred classes for cases in a testing dataset.It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. Cohen's kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless.\n",
        "\n"
      ],
      "metadata": {
        "id": "SP_L9x-G-pIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Describe the model ensemble method. In machine learning, what part does it play?\n",
        "\n",
        "Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model . To better understand this definition lets take a step back into ultimate goal of machine learning and model building.\n",
        "\n",
        "Ensemble methods usually produces more accurate solutions than a single model would. This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods.\n",
        "\n",
        "Voting and averaging are two of the easiest ensemble methods. They are both easy to understand and implement. Voting is used for classification and averaging is used for regression\n"
      ],
      "metadata": {
        "id": "5qjJBK9F_Fnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve.\n",
        "\n",
        "A descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it. A geometric model or spatial model is a descriptive model that represents geometric and/or spatial relationships.\n",
        "\n",
        "Examples of descriptive analytics include KPIs such as year-on-year percentage sales growth, revenue per customer and the average time customers take to pay bills. The products of descriptive analytics appear in financial statements, other reports, dashboards and presentations"
      ],
      "metadata": {
        "id": "737vXCwn_sT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Describe how to evaluate a linear regression model.\n",
        "\n",
        "There are 3 main metrics for model evaluation in regression:\n",
        "\n",
        "R Square/Adjusted R Square.\n",
        "\n",
        "Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
        "\n",
        "Mean Absolute Error(MAE)"
      ],
      "metadata": {
        "id": "bBlzFzOSADkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Distinguish:\n",
        "\n",
        "1.Descriptive vs. predictive models:\n",
        "\n",
        "A descriptive model will exploit the past data that are stored in databases and provide you with the accurate report. In a Predictive model, it identifies patterns found in past and transactional data to find risks and future outcomes.\n",
        "\n",
        "2.Underfitting vs. overfitting the model:\n",
        "\n",
        "Model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data.\n",
        "Model is underfitting the training data when the model performs poorly on the training data.\n",
        "\n",
        "3.Bootstrapping vs. cross-validation:\n",
        "\n",
        "Cross validation splits the available dataset to create multiple datasets, and Bootstrapping method uses the original dataset to create multiple datasets after resampling with replacement. Bootstrapping it is not as strong as Cross validation when it is used for model validation.\n",
        "\n"
      ],
      "metadata": {
        "id": "dEyyFRsOAOlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Make quick notes on:\n",
        "\n",
        "1.LOOCV.\n",
        "\n",
        "LOOCV(Leave One Out Cross-Validation) is a type of cross-validation approach in which each observation is considered as the validation set and the rest (N-1) observations are considered as the training set. In LOOCV, fitting of the model is done and predicting using one observation validation set.\n",
        "\n",
        "2.F-measurement:\n",
        "\n",
        "The F-measure can be viewed as a compromise between recall and precision. It is high only when both recall and precision are high. It is equivalent to recall when α = 0 and precision when α = 1. The F-measure assumes values in the interval [0,1].\n",
        "\n",
        "3.The width of the silhouette:\n",
        "\n",
        "A silhouette is the image of a person, animal, object or scene represented as a solid shape of a single colour, usually black, with its edges matching the outline of the subject.\n",
        "\n",
        "\n",
        "4.Receiver operating characteristic curve:\n",
        "\n",
        "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers starting in 1941, which led to its name."
      ],
      "metadata": {
        "id": "PtYrXfBnBGg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s9jISTZ5ALXu"
      }
    }
  ]
}