{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCkIX4Qs04HeEVtfDSi8q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Machine-Learning-Assignments/blob/main/Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What exactly is a feature? Give an example to illustrate your point.\n",
        "\n",
        "The definition of a feature is a part of the face, a quality, a special attraction, article or a major film showing in the theatre. An example of feature is a nose. An example of feature is freckles. An example of feature is a new movie coming out."
      ],
      "metadata": {
        "id": "V6c_DOfeaQw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What are the various circumstances in which feature construction is required?\n",
        "\n",
        "Feature construction is a process which builds intermediate features from the original descriptors in a dataset. The aim is to build more efficient features for a machine data mining task."
      ],
      "metadata": {
        "id": "8bm_DNe_aZxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Describe how nominal variables are encoded.\n",
        "\n",
        "A column with nominal data has values that cannot be ordered in any meaningful way. Nominal data is most often one-hot (aka dummy) encoded, but there are many options that might perform better for machine learning."
      ],
      "metadata": {
        "id": "GBfurKWmalnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Describe how numeric features are converted to categorical features.\n",
        "\n",
        "In machine-learning literature, the process is usually called discretization of continuous data. Very few machine-learning algorithms work with mixed data, so you can convert the numeric data to categorical data and then use a machine-learning algorithm that works with categorical data"
      ],
      "metadata": {
        "id": "84UxuKpzaxC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this\n",
        "approach?\n",
        "\n",
        "For a dataset with d input features, the feature selection process results in k features such that k < d, where k is the smallest set of significant and relevant features. Training a machine learning algorithm faster. Reducing the complexity of a model and making it easier to interpret."
      ],
      "metadata": {
        "id": "dmTOLkpka_OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.When is a feature considered irrelevant? What can be said to quantify it?\n",
        "\n"
      ],
      "metadata": {
        "id": "1QBSZ5k-bEMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 When is a function considered redundant? What criteria are used to identify features that could\n",
        "be redundant?\n",
        "\n",
        "For example, if two features {X1, X2} are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure. In other words, the correlation measure provides statistical association between any given a pair of features.\n"
      ],
      "metadata": {
        "id": "gQdZTUXPbL8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are the various distance measurements used to determine feature similarity?\n",
        "\n",
        "Hamming Distance. Hamming Distance measures the similarity between two strings of the same length. The Hamming Distance between two strings of the same length is the number of positions at which the corresponding characters are different. Since the length of these strings is equal, we can calculate the Hamming Distance"
      ],
      "metadata": {
        "id": "MJ7iJb3pbTCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.State difference between Euclidean and Manhattan distances?\n",
        "\n",
        "Euclidean distance is the shortest path between source and destination which is a straight line as shown in Figure 1.3. but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines "
      ],
      "metadata": {
        "id": "-tTiyXD1baMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Distinguish between feature transformation and feature selection.\n",
        "\n",
        "The key difference between feature selection and feature extraction techniques used for dimensionality reduction is that while the original features are maintained in the case of feature selection algorithms, the feature extraction algorithms transform the data onto a new feature space."
      ],
      "metadata": {
        "id": "8ytLhp9ybgf9"
      }
    }
  ]
}