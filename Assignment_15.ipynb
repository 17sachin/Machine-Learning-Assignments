{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeTV8K8H8ylYf9qU2PMYJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Machine-Learning-Assignments/blob/main/Assignment_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n",
        "\n",
        "Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled data points. Unsupervised learning does not have (or need) any labeled outputs, so its goal is to infer the natural structure present within a set of data points"
      ],
      "metadata": {
        "id": "dqR2IfBkii-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Describe in detail any five examples of classification problems.\n",
        "\n",
        "1 - Email Spam. \n",
        "\n",
        "2 - Handwritten Digit Recognition. \n",
        "\n",
        "3 - Image segmentation. \n",
        "\n",
        "4 - Speech Recognition. \n",
        "\n",
        "5 - DNA Expression Microarray. "
      ],
      "metadata": {
        "id": "PA77Oi6linm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Describe each phase of the classification process in detail.\n",
        "\n",
        "Generally the biomedical data classification process can be divided into four phases, namely (1) data acquisition and segmentation, (2) data preprocessing, (3) feature extraction/dimension reduction, and (4) recognition and classification."
      ],
      "metadata": {
        "id": "AvUHg0IwiyV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Go through the SVM model in depth using various scenarios.\n",
        "\n",
        "“Support Vector Machine” (SVM) is a supervised machine learning algorithm that can be used for both classification or regression challenges. However, it is mostly used in classification problems."
      ],
      "metadata": {
        "id": "rFxAo2tFi4do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are some of the benefits and drawbacks of SVM?\n",
        "\n",
        "SVM's are very good when we have no idea on the data.\n",
        "Works well with even unstructured and semi structured data like text, Images and trees.\n",
        "The kernel trick is real strength of SVM. ...\n",
        "Unlike in neural networks, SVM is not solved for local optima."
      ],
      "metadata": {
        "id": "IrT-AB3zi9RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Go over the kNN model in depth.\n",
        "\n",
        "kNN classifier determines the class of a data point by majority voting principle. If k is set to 5, the classes of 5 closest points are checked. Prediction is done according to the majority class. Similarly, kNN regression takes the mean value of 5 closest points."
      ],
      "metadata": {
        "id": "8RSYl8G6jCZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Discuss the kNN algorithm&#39;s error rate and validation error.\n",
        "\n",
        "The error rate at K=1 is always zero for the training sample. This is because the closest point to any training data point is itself. Hence it'll always overfit. You should try out different K values on a validation set and plot the validation error"
      ],
      "metadata": {
        "id": "WadaMfNvjIi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.For kNN, talk about how to measure the difference between the test and training results.\n",
        "\n",
        "The k-nearest neighbour classification (k-NN) is one of the most popular distance-based algorithms. This classification is based on measuring the distances between the test sample and the training samples to determine the final classification output. The traditional k-NN classifier works naturally with numerical data"
      ],
      "metadata": {
        "id": "8aryvASpjP0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Describe the different ways to scan a decision tree.\n",
        "\n",
        "Define the problem area for which decision making is necessary.\n",
        "\n",
        "Draw a decision tree with all possible solutions and their consequences.\n",
        "\n",
        "Input relevant variables with their respective probability values.\n",
        "\n",
        "Determine and allocate payoffs for each possible outcome."
      ],
      "metadata": {
        "id": "TQo4x_XtjaiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.Describe in depth the decision tree algorithm.\n",
        "\n",
        "Tree depth is a measure of how many splits a tree can make before coming to a prediction. This process could be continued further with more splitting until the tree is as pure as possible"
      ],
      "metadata": {
        "id": "_pfPR146jif5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.In a decision tree, what is inductive bias? What would you do to stop overfitting?\n",
        "\n",
        "The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered. ... The kind of necessary assumptions about the nature of the target function are subsumed in the phrase inductive bias."
      ],
      "metadata": {
        "id": "vArt1dz3jqso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.Explain advantages and disadvantages of using a decision tree?\n",
        "\n",
        "Advantages and Disadvantages of Decision Trees in Machine Learning. Decision Tree is used to solve both classification and regression problems. But the main drawback of Decision Tree is that it generally leads to overfitting of the data"
      ],
      "metadata": {
        "id": "geiWsZrajwl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.Describe in depth the problems that are suitable for decision tree learning.\n",
        "\n",
        "The weaknesses of decision tree methods : Decision trees are less appropriate for estimation tasks where the goal is to predict the value of a continuous attribute. Decision trees are prone to errors in classification problems with many class and relatively small number of training examples"
      ],
      "metadata": {
        "id": "aK0IK7Uej04R"
      }
    }
  ]
}