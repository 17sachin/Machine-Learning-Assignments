{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqi7TpbP9CujlnAL7GYU5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Machine-Learning-Assignments/blob/main/Assignment_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.In a linear equation, what is the difference between a dependent variable and an independent\n",
        "variable?\n",
        "\n",
        "Algebraically, a linear equation typically takes the form y = mx + b, where m and b are constants, x is the independent variable, y is the dependent variable. ... The slope tells us how the dependent variable (y) changes for every one unit increase in the independent (x) variable, on average."
      ],
      "metadata": {
        "id": "WfF_1Va5kaEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is the concept of simple linear regression? Give a specific example.\n",
        "\n",
        "You can use simple linear regression when you want to know: How strong the relationship is between two variables (e.g. the relationship between rainfall and soil erosion). The value of the dependent variable at a certain value of the independent variable (e.g. the amount of soil erosion at a certain level of rainfall)"
      ],
      "metadata": {
        "id": "u2SF6uFfkeZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.In a linear regression, define the slope.\n",
        "\n",
        "A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. ... The slope of the line is b, and a is the intercept (the value of y when x = 0)."
      ],
      "metadata": {
        "id": "cqY0TO9pkjFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Determine the graph&#39;s slope, where the lower point on the line is represented as (3, 2) and the\n",
        "higher point is represented as (2, 2)."
      ],
      "metadata": {
        "id": "pHxHDeYakn-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.In linear regression, what are the conditions for a positive slope?\n",
        "\n",
        "Linearity: The relationship between X and the mean of Y is linear. Homoscedasticity: The variance of residual is the same for any value of X. Independence: Observations are independent of each other. Normality: For any fixed value of X, Y is normally distributed"
      ],
      "metadata": {
        "id": "94x4JMCBkqLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.In linear regression, what are the conditions for a negative slope?\n",
        "\n",
        "If the slope is negative, y decreases as x increases and the function runs downhill. If the slope is zero, y does not change, thus is constant—a horizontal line."
      ],
      "metadata": {
        "id": "Bq5TogD-kx8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What is multiple linear regression and how does it work?\n",
        "\n",
        "Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. Multiple regression is an extension of linear (OLS) regression that uses just one explanatory variable."
      ],
      "metadata": {
        "id": "SJBMyRnUk2e6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.In multiple linear regression, define the number of squares due to error.\n",
        "\n",
        "A residual (error) term is calculated as e i = y i − y ^ i , the difference between an actual and a predicted value of y."
      ],
      "metadata": {
        "id": "7XahSjgrk79x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.In multiple linear regression, define the number of squares due to regression.\n",
        "\n",
        "MSE is calculated by: measuring the distance of the observed y-values from the predicted y-values at each value of x; squaring each of these distances; calculating the mean of each of the squared distances."
      ],
      "metadata": {
        "id": "SBob0CTPlFnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is heteroskedasticity, and what does it mean?\n",
        "\n",
        "As it relates to statistics, heteroskedasticity (also spelled heteroscedasticity) refers to the error variance, or dependence of scattering, within a minimum of one independent variable within a particular sample. ... A common cause of variances outside the minimum requirement is often attributed to issues of data quality."
      ],
      "metadata": {
        "id": "4-rg-M40lMHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.Describe the concept of ridge regression.\n",
        "\n",
        "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. ... By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors. It is hoped that the net effect will be to give estimates that are more reliable."
      ],
      "metadata": {
        "id": "1roaD_MLlUFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.Describe the concept of lasso regression.\n",
        "\n",
        "Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters). ... The acronym “LASSO” stands for Least Absolute Shrinkage and Selection Operator."
      ],
      "metadata": {
        "id": "O8RiVngTlZMS"
      }
    }
  ]
}